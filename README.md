# ETL Project
### Extract, Transform, and Load datasets into one large clean data set. Project in Dataviz class.


## Group: Carlie Azar, Dave Moorman, Jake Geiser, Andrea Pappa

## Extract 
### I. Sources:
#### A. https://www.kaggle.com/blitzr/movehub-city-rankings?select=cities.csv
#### B. https://www.kaggle.com/blitzr/movehub-city-rankings?select=movehubcostofliving.csv
#### C. https://www.movehub.com/city-rankings/
#### D. https://www.movehub.com/city-rankings/
#### E. https://en.wikipedia.org/wiki/List_of_towns_and_cities_with_100,000_or_more_inhabitants/cityname:_A

### II. We extracted 3 CSVs  from Kaggle examining an expanse of cities around the world, their cost of living, and quality of life. Using ETL methodology, we will be investigating municipalities where the population exceeds 100,000. After extracting data from the CSVs, we will reconstruct our findings and reload them into a relational database.  

## Transform 
### I. Python, Pandas, and SQL will be used to clean, filter, and aggregate the data. We will also bring in SQLAlchemy as another open-source tool and object relational mapper (ORM).

## Load 
### I. Loading data into a relational database for referencing and analysis

